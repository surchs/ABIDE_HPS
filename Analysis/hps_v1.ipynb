{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the HPS model to run\n",
    "- get the inputs correct\n",
    "- run through all steps\n",
    "- get an accuracy estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/surchs/git/Proteus/')\n",
    "from proteus.predic import high_confidence\n",
    "#from proteus.predic import prediction\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import sklearn as skl\n",
    "import seaborn as sbn\n",
    "import scipy.io as sio\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "#warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "root_p = '/home/surchs/sim_big/PROJECT/abide_hps/'\n",
    "# Pheno\n",
    "sample_p = os.path.join(root_p, 'pheno', 'psm_abide1.csv')\n",
    "# Data\n",
    "resid_ct_p = os.path.join(root_p, 'residual', 'ct_30mm_residual_psm.npy')\n",
    "resid_fc_p = os.path.join(root_p, 'residual', 'sd_30mm_residual_psm.npy')\n",
    "mask_p = os.path.join(root_p, 'mask', 'MIST_mask.nii.gz')\n",
    "subtype_fc_p = os.path.join(root_p, 'subtypes', 'subtypes_fc.npz')\n",
    "subtype_ct_p = os.path.join(root_p, 'subtypes', 'subtypes_ct.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "sample = pd.read_csv(sample_p)\n",
    "sample['DX_CODE'] = sample['DX_GROUP'].replace({'Autism':1, 'Control':0})\n",
    "s_fc = np.load(subtype_fc_p)\n",
    "s_ct = np.load(subtype_ct_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape FC to add to the table\n",
    "fc_weights = np.reshape(s_fc['weights'], (370, 5*20))\n",
    "fc_cols = ['fc_n{}_s{}'.format(nid+1, sid+1) for sid in range(5) for nid in range(20)]\n",
    "# Same for CT\n",
    "ct_weights = s_ct['weights']\n",
    "ct_cols = ['ct_s{}'.format(sid+1) for sid in range(5)]\n",
    "# Combine both\n",
    "weights = np.concatenate((ct_weights, fc_weights),1)\n",
    "cols = ct_cols + fc_cols\n",
    "# Into a pandas DF\n",
    "w_data = pd.DataFrame(data=weights, columns=cols)\n",
    "# Combine both for the full dataset\n",
    "dataset = sample.join(w_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the features\n",
    "scaler = skl.preprocessing.StandardScaler()\n",
    "# Add BV to the subtype weights\n",
    "col_features = ['BV'] + cols\n",
    "\n",
    "# Build features\n",
    "x_ = dataset.loc[:, col_features]\n",
    "# Take the numeric diagnosis code\n",
    "y_ = dataset.loc[:, ['DX_CODE']].values.squeeze()\n",
    "# Normalize\n",
    "x_ = scaler.fit_transform(x_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1\n",
      "Stage 2\n",
      "Classifying TDC vs ASD...\n",
      "[ 0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.\n",
      "  1.  0.  1.  1.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.\n",
      "  1.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  0.  1.  1.  0.  0.\n",
      "  1.  0.  1.  1.  0.  0.  0.  1.  1.  0.  1.  0.  1.  0.  0.  0.  1.  0.\n",
      "  0.  1.  0.  1.  0.  1.  0.  0.  1.  1.  0.  1.  1.  0.  0.  1.  0.  1.\n",
      "  1.  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  1.  1.\n",
      "  1.  1.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  1.]\n",
      "Stage 1\n",
      "Stage 2\n",
      "Classifying TDC vs ASD...\n",
      "[ 0.  1.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.  0.  0.  1.\n",
      "  0.  1.  0.  0.  1.  1.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  1.  0.  1.  0.  1.  1.  1.  1.  1.  0.  0.  0.  1.  1.  0.  0.  1.\n",
      "  1.  0.  0.  1.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  1.  1.  1.  0.  1.  1.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.  0.\n",
      "  1.  1.  0.  1.  0.  1.  1.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.\n",
      "  0.  1.  1.  1.  1.  1.  1.  0.  0.  0.  1.  1.  0.  0.  1.  0.]\n",
      "Stage 1\n",
      "Stage 2\n",
      "Classifying TDC vs ASD...\n",
      "[ 0.  1.  1.  0.  1.  1.  1.  1.  1.  1.  0.  1.  0.  0.  1.  1.  0.  1.\n",
      "  1.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.\n",
      "  1.  1.  0.  1.  0.  1.  1.  1.  1.  0.  0.  0.  1.  1.  0.  1.  0.  0.\n",
      "  1.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.\n",
      "  0.  1.  0.  0.  1.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.  1.  0.\n",
      "  1.  1.  1.  1.  0.  1.  1.  1.  0.  1.  0.  0.  1.  1.  1.  0.  1.  1.\n",
      "  0.  1.  0.  1.  1.  1.  1.  0.  1.  0.  0.  1.  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "# Prep store\n",
    "store = {key:list() for key in ['accuracy_overall',\n",
    "                                'accuracy_asd',\n",
    "                                'precision_asd',\n",
    "                                'precision_tdc',\n",
    "                                'recall_asd',\n",
    "                                'recall_tdc',\n",
    "                                'f1_asd',\n",
    "                                'f1_tdc'\n",
    "                               ]}\n",
    "\n",
    "# Run the model and see where that gets us\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "for train_index, val_index in skf.split(x_,y_):\n",
    "    X_training, X_val = x_[train_index], x_[val_index]\n",
    "    y_training, y_val = y_[train_index], y_[val_index]\n",
    "    \n",
    "    hpc = high_confidence.TwoStagesPrediction(\n",
    "        n_iter=500,\n",
    "        shuffle_test_split=0.5,\n",
    "        min_gamma=.90,\n",
    "        gamma=0.95,\n",
    "        thresh_ratio=0.1,\n",
    "        verbose=False)\n",
    "    \n",
    "    hpc.fit(X_training, X_training, y_training)\n",
    "    _, dic_results = hpc.predict(X_val, X_val)\n",
    "    acc = skl.metrics.accuracy_score(y_val, (dic_results['s1df'][:,0]>0).astype(float))\n",
    "    store['accuracy_overall'].append(acc)\n",
    "    \n",
    "    # Get the guys we think are ASD\n",
    "    pos_mask = (dic_results['s2df'][:,1]>0)\n",
    "    acc_s2 = skl.metrics.accuracy_score(y_val[pos_mask], (dic_results['s1df'][:,0]>0).astype(float)[pos_mask])\n",
    "    store['accuracy_asd'].append(acc_s2)\n",
    "    \n",
    "    print('Classifying TDC vs ASD...')\n",
    "    print((dic_results['s1df'][:,0]>0).astype(float))\n",
    "    \n",
    "    y_pred = (dic_results['s1df'][:,0]>0).astype(float)\n",
    "    # Compute precision of the classifier for ASD\n",
    "    asd_p = skl.metrics.precision_score(y_val, y_pred, pos_label=1)\n",
    "    store['precision_asd'].append(asd_p)\n",
    "    # Compute precision of the classifier for TDC\n",
    "    tdc_p = skl.metrics.precision_score(y_val, y_pred, pos_label=0)\n",
    "    store['precision_tdc'].append(tdc_p)\n",
    "    # Recall Ratio of ASD label\n",
    "    asd_r = skl.metrics.recall_score(y_val, y_pred, pos_label=1)\n",
    "    store['recall_asd'].append(asd_r)\n",
    "    # Recall Ratio of TDC label\n",
    "    tdc_r = skl.metrics.recall_score(y_val, y_pred, pos_label=0)\n",
    "    store['recall_tdc'].append(tdc_r)\n",
    "    # F1 Ratio of ASD label\n",
    "    asd_f = skl.metrics.f1_score(y_val, y_pred, pos_label=1)\n",
    "    store['f1_asd'].append(asd_f)\n",
    "    # Recall Ratio of TDC label\n",
    "    tdc_f = skl.metrics.f1_score(y_val, y_pred, pos_label=0)\n",
    "    store['f1_tdc'].append(tdc_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean stage 1 validation accuracy:  0.57055349903\n",
      "Mean stage 2 accuracy:  0.872474747475\n",
      "Mean precision for ASD:  0.56087467309\n",
      "Mean precision for TDC:  0.580796980797\n",
      "Mean recall for ASD:  0.566484517304\n",
      "Mean recall for TDC:  0.574500768049\n",
      "Mean f1 score for ASD:  0.563040771864\n",
      "Mean f1 score for TDC:  0.576976716813\n"
     ]
    }
   ],
   "source": [
    "#print(scores_ad_cn)\n",
    "print('Mean stage 1 validation accuracy: ',np.mean(store['accuracy_overall']))\n",
    "#print(scores_s2)\n",
    "print('Mean stage 2 accuracy: ', np.mean(store['accuracy_asd']))\n",
    "#print(ad_precision)\n",
    "print('Mean precision for ASD: ',np.mean(store['precision_asd']))\n",
    "#print(cn_precision)\n",
    "print('Mean precision for TDC: ',np.mean(store['precision_tdc']))\n",
    "#print(ad_recall)\n",
    "print('Mean recall for ASD: ',np.mean(store['recall_asd']))\n",
    "#print(cn_recall)\n",
    "print('Mean recall for TDC: ',np.mean(store['recall_tdc']))\n",
    "#print(ad_f1_score)\n",
    "print('Mean f1 score for ASD: ',np.mean(store['f1_asd']))\n",
    "#print(cn_f1_score)\n",
    "print('Mean f1 score for TDC: ',np.mean(store['f1_tdc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1\n",
      "Stage 2\n",
      "Classifying TDC vs ASD...\n",
      "[ 0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.\n",
      "  1.  0.  1.  1.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.\n",
      "  1.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  0.  1.  1.  0.  0.\n",
      "  1.  0.  1.  1.  0.  0.  0.  1.  1.  0.  1.  0.  1.  0.  0.  0.  1.  0.\n",
      "  0.  1.  0.  1.  0.  1.  0.  0.  1.  1.  0.  1.  1.  0.  0.  1.  0.  1.\n",
      "  1.  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  1.  1.\n",
      "  1.  1.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  1.]\n",
      "Total number of TARGET subjects:  61\n",
      "Total number of NON-TARGET subjects:  63\n",
      "Stage 1 number of hits (true and false positives):  58.0\n",
      "Stage 1 TRUE positives:  30.0\n",
      "Stage 1 FALSE positives:  28.0\n",
      "Stage 1 TRUE negatives:  35.0\n",
      "Total number of flagged HPC-AD subjects:  8.0\n",
      "Number of flagged HPC-AD subjects that are TRUE positives:  7\n",
      "Number of flagged HPC-AD subjects that are FALSE positives:  1.0\n",
      "Number of true negatives:  62.0\n",
      "#############################\n",
      "Stage 1 stats for TARGET vs NON-TARGET\n",
      "Precision for AD:  0.51724137931\n",
      "Recall (or sensitivity)  for AD:  0.491803278689\n",
      "Specificity:  0.555555555556\n",
      "Adjusted precision for 33.6% baseline rate:  0.358951633325\n",
      "Accuracy:  0.524193548387\n",
      "#############################\n",
      "Stage 2 stats for TARGET vs NON-TARGET\n",
      "Precision for HPC-AD:  0.875\n",
      "Recall (or sensitivity) for HPC-AD:  0.114754098361\n",
      "Specificity:  0.984126984127\n",
      "Adjusted precision for 33.6% baseline rate:  0.785329658681\n",
      "Accuracy:  0.556451612903\n",
      "Stage 1\n",
      "Stage 2\n",
      "Classifying TDC vs ASD...\n",
      "[ 0.  1.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.  0.  0.  1.\n",
      "  0.  1.  0.  0.  1.  1.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  1.  0.  1.  0.  1.  1.  1.  1.  1.  0.  0.  0.  1.  1.  0.  0.  1.\n",
      "  1.  0.  0.  1.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  1.  1.  1.  0.  1.  1.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.  0.\n",
      "  1.  1.  0.  1.  0.  1.  1.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.\n",
      "  0.  1.  1.  1.  1.  1.  1.  0.  0.  0.  1.  1.  0.  0.  1.  0.]\n",
      "Total number of TARGET subjects:  61\n",
      "Total number of NON-TARGET subjects:  63\n",
      "Stage 1 number of hits (true and false positives):  59.0\n",
      "Stage 1 TRUE positives:  33.0\n",
      "Stage 1 FALSE positives:  26.0\n",
      "Stage 1 TRUE negatives:  37.0\n",
      "Total number of flagged HPC-AD subjects:  11.0\n",
      "Number of flagged HPC-AD subjects that are TRUE positives:  10\n",
      "Number of flagged HPC-AD subjects that are FALSE positives:  1.0\n",
      "Number of true negatives:  62.0\n",
      "#############################\n",
      "Stage 1 stats for TARGET vs NON-TARGET\n",
      "Precision for AD:  0.559322033898\n",
      "Recall (or sensitivity)  for AD:  0.540983606557\n",
      "Specificity:  0.587301587302\n",
      "Adjusted precision for 33.6% baseline rate:  0.398792451451\n",
      "Accuracy:  0.564516129032\n",
      "#############################\n",
      "Stage 2 stats for TARGET vs NON-TARGET\n",
      "Precision for HPC-AD:  0.909090909091\n",
      "Recall (or sensitivity) for HPC-AD:  0.16393442623\n",
      "Specificity:  0.984126984127\n",
      "Adjusted precision for 33.6% baseline rate:  0.839387114171\n",
      "Accuracy:  0.58064516129\n",
      "Stage 1\n",
      "Stage 2\n",
      "Classifying TDC vs ASD...\n",
      "[ 0.  1.  1.  0.  1.  1.  1.  1.  1.  1.  0.  1.  0.  0.  1.  1.  0.  1.\n",
      "  1.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.\n",
      "  1.  1.  0.  1.  0.  1.  1.  1.  1.  0.  0.  0.  1.  1.  0.  1.  0.  0.\n",
      "  1.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.\n",
      "  0.  1.  0.  0.  1.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.  1.  0.\n",
      "  1.  1.  1.  1.  0.  1.  1.  1.  0.  1.  0.  0.  1.  1.  1.  0.  1.  1.\n",
      "  0.  1.  0.  1.  1.  1.  1.  0.  1.  0.  0.  1.  0.  1.]\n",
      "Total number of TARGET subjects:  60\n",
      "Total number of NON-TARGET subjects:  62\n",
      "Stage 1 number of hits (true and false positives):  66.0\n",
      "Stage 1 TRUE positives:  40.0\n",
      "Stage 1 FALSE positives:  26.0\n",
      "Stage 1 TRUE negatives:  36.0\n",
      "Total number of flagged HPC-AD subjects:  24.0\n",
      "Number of flagged HPC-AD subjects that are TRUE positives:  20\n",
      "Number of flagged HPC-AD subjects that are FALSE positives:  4.0\n",
      "Number of true negatives:  58.0\n",
      "#############################\n",
      "Stage 1 stats for TARGET vs NON-TARGET\n",
      "Precision for AD:  0.606060606061\n",
      "Recall (or sensitivity)  for AD:  0.666666666667\n",
      "Specificity:  0.58064516129\n",
      "Adjusted precision for 33.6% baseline rate:  0.445814072933\n",
      "Accuracy:  0.622950819672\n",
      "#############################\n",
      "Stage 2 stats for TARGET vs NON-TARGET\n",
      "Precision for HPC-AD:  0.833333333333\n",
      "Recall (or sensitivity) for HPC-AD:  0.333333333333\n",
      "Specificity:  0.935483870968\n",
      "Adjusted precision for 33.6% baseline rate:  0.723333333333\n",
      "Accuracy:  0.639344262295\n"
     ]
    }
   ],
   "source": [
    "# Run the model and see where that gets us\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "for train_index, val_index in skf.split(x_,y_):\n",
    "    X_training, X_val = x_[train_index], x_[val_index]\n",
    "    y_training, y_val = y_[train_index], y_[val_index]\n",
    "    \n",
    "    hpc = high_confidence.TwoStagesPrediction(\n",
    "        n_iter=500,\n",
    "        shuffle_test_split=0.5,\n",
    "        min_gamma=.90,\n",
    "        gamma=0.95,\n",
    "        thresh_ratio=0.1,\n",
    "        verbose=False)\n",
    "    \n",
    "    hpc.fit(X_training, X_training, y_training)\n",
    "    _, dic_results = hpc.predict(X_val, X_val)\n",
    "    acc = skl.metrics.accuracy_score(y_val, (dic_results['s1df'][:,0]>0).astype(float))\n",
    "    store['accuracy_overall'].append(acc)\n",
    "    \n",
    "    # Get the guys we think are ASD\n",
    "    pos_mask = (dic_results['s2df'][:,1]>0)\n",
    "    acc_s2 = skl.metrics.accuracy_score(y_val[pos_mask], (dic_results['s1df'][:,0]>0).astype(float)[pos_mask])\n",
    "    store['accuracy_asd'].append(acc_s2)\n",
    "    \n",
    "    print('Classifying TDC vs ASD...')\n",
    "    print((dic_results['s1df'][:,0]>0).astype(float))\n",
    "    array_results, dic_results = hpc.predict(X_val, X_val)\n",
    "    y_pred = (dic_results['s1df'][:,0]>0).astype(float)\n",
    "    lr_decision = dic_results['s2df'][:,1]\n",
    "    predic_stats(y_val, y_pred, lr_decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do it without crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1\n",
      "Proba:\n",
      "[ 0.92887029  0.81712062  0.95546559  0.98809524  0.08898305  0.07531381\n",
      "  0.61445783  0.16269841  0.0037594   0.99609375  0.37606838  0.04705882\n",
      "  0.52916667  0.93415638  0.89285714  0.452       0.84942085  0.97580645\n",
      "  0.8         0.03643725  0.82478632  0.85714286  0.92217899  0.92913386\n",
      "  0.03212851  0.84337349  0.92337165  0.73745174  0.15185185  0.75652174\n",
      "  0.17870722  0.7421875   0.98069498  0.87096774  0.50607287  0.1547619\n",
      "  0.1496063   0.79148936  0.3633218   0.17647059  0.7125      0.99568966\n",
      "  0.19444444  0.94444444  0.34126984  0.          1.          0.003663\n",
      "  0.43410853  0.99596774  0.91666667  0.88047809  0.49596774  0.7012987\n",
      "  0.50632911  0.97142857  0.06097561  0.24045802  0.23430962  0.15510204\n",
      "  0.08627451  0.87148594  0.92307692  1.          0.06319703  0.24609375\n",
      "  0.98672566  0.98837209  0.58102767  0.61946903  0.90598291  0.50196078\n",
      "  0.33870968  0.92913386  0.42        0.640625    0.04098361  0.97769517\n",
      "  0.6284585   0.18859649  0.63671875  0.3151751   0.09349593  0.26459144\n",
      "  0.86234818  0.19272727  0.07539683  0.97297297  0.40080972  0.85654008\n",
      "  1.          0.07171315  0.32539683  0.25550661  0.23293173  0.99590164\n",
      "  0.47177419  0.59765625  0.49193548  0.1314741   0.          1.          0.9484127\n",
      "  0.97468354  0.98490566  0.99609375  0.96551724  0.26754386  0.82397004\n",
      "  0.16269841  0.45454545  1.          0.48917749  0.61983471  0.95\n",
      "  0.67729084  0.79411765  0.70750988  0.          0.00790514  0.68220339\n",
      "  0.31274131  0.9958159   0.88065844  0.97142857  0.42084942  0.6870229\n",
      "  0.9375      1.          0.02811245  0.51162791  0.0242915   0.67871486\n",
      "  0.14876033  0.06882591  0.51882845  0.01612903  0.77289377  0.55263158\n",
      "  0.33204633  0.87449393  0.28787879  0.96551724  0.82375479  0.85877863\n",
      "  0.54098361  0.2992126   0.64016736  0.12601626  0.04329004  0.77372263\n",
      "  0.69348659  0.02521008  0.91855204  0.97188755  0.99176955  0.96326531\n",
      "  0.06976744  0.67622951  0.5952381   0.9486166   0.41287879  0.94715447\n",
      "  0.43873518  0.65098039  0.03831418  0.048       0.51587302  0.59143969\n",
      "  0.60344828  0.90495868  0.82329317  0.06425703  0.0125      1.\n",
      "  0.72427984  0.05439331  0.94573643  1.          0.70522388  0.33212996\n",
      "  0.94676806  0.86666667  0.          0.85892116  0.21632653  0.83739837\n",
      "  0.11836735  0.98031496  0.97530864  0.06153846  0.99230769  0.02083333\n",
      "  0.99170124  0.98507463  1.          0.98814229  0.28571429  0.23893805\n",
      "  0.          0.4125      0.20247934  0.93675889  0.4015444   0.\n",
      "  0.76305221  0.99563319  0.72834646  0.56016598  0.99583333  0.75833333\n",
      "  0.89962825  0.2183908   0.94285714  0.98425197  0.8097166   0.16872428\n",
      "  0.5620155   0.42040816  0.16078431  0.52362205  0.744       1.\n",
      "  0.98484848  0.04016064  0.99607843  0.58299595  0.87644788  1.\n",
      "  0.99578059  0.64705882  0.88934426  0.39915966  0.04115226  0.23360656\n",
      "  0.23643411  0.93283582  0.2195122   0.57676349  0.0460251   0.00384615\n",
      "  0.52777778  1.          0.22988506  0.52222222  1.          0.93050193\n",
      "  0.95454545  0.99610895  1.          0.1953125   0.94584838  0.05932203\n",
      "  0.06463878  0.18367347  0.94047619  0.11278195  0.98706897  0.91497976\n",
      "  0.57831325  0.22357724  0.99196787  0.96456693  0.11904762  0.60557769\n",
      "  0.13675214  0.06198347  0.84291188  0.16479401  0.70562771  0.52631579\n",
      "  0.91472868  1.          0.12355212  0.91902834  0.85660377  0.48790323\n",
      "  0.15315315  0.02409639  0.42578125  0.50420168  0.30125523  0.96707819\n",
      "  0.51004016  0.23443223  0.42629482  0.73895582  0.84615385  0.96311475\n",
      "  0.91481481  0.46938776  0.89539749  0.80578512  0.99632353  0.91286307\n",
      "  0.99595142  0.79835391  0.59915612  0.99612403  0.20883534  0.91129032\n",
      "  0.71481481  0.          0.992       0.88030888  0.57915058  0.87443946\n",
      "  0.40225564  0.78137652  0.88163265  1.          0.75303644  0.16731518\n",
      "  0.98387097  0.79237288  0.69361702  0.87603306  0.89316239  0.89068826\n",
      "  0.71900826  0.86746988  0.32627119  0.99598394  1.          0.0125\n",
      "  0.36882129  0.8487395   0.99190283  0.16078431  0.0464135   0.99619772\n",
      "  0.77821012  1.          0.36501901  0.83467742  1.          0.99604743\n",
      "  0.          0.96721311  0.84108527  1.          1.          0.12598425\n",
      "  0.925       1.          0.2890625   0.25        0.51476793  0.54724409\n",
      "  0.59677419  1.          0.92692308  0.5         0.16044776  0.70305677\n",
      "  1.          0.09881423  1.          0.09677419  0.95330739  0.95121951\n",
      "  0.12773723  0.890625    0.15057915  0.72941176  0.36111111  0.00413223\n",
      "  0.14937759  0.33590734  0.97286822]\n",
      "Average hm score 0.305405405405\n",
      "Stage 2\n",
      "Adjusted gamma:  0.9\n",
      "Adjusted gamma:  0.9\n"
     ]
    }
   ],
   "source": [
    "#reload(high_confidence)\n",
    "hpc = high_confidence.TwoStagesPrediction(\n",
    "    n_iter=500,\n",
    "    shuffle_test_split=0.5,\n",
    "    min_gamma=.9,\n",
    "    thresh_ratio=0.1, gamma=0.9)\n",
    "\n",
    "hpc.fit(x_, x_, y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hpc.gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_results, dic_results = hpc.predict(x_, x_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (dic_results['s1df'][:,0]>0).astype(float)\n",
    "lr_decision = dic_results['s2df'][:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of TARGET subjects:  182\n",
      "Total number of NON-TARGET subjects:  188\n",
      "Stage 1 number of hits (true and false positives):  178.0\n",
      "Stage 1 TRUE positives:  126.0\n",
      "Stage 1 FALSE positives:  52.0\n",
      "Stage 1 TRUE negatives:  136.0\n",
      "Total number of flagged HPC-AD subjects:  68.0\n",
      "Number of flagged HPC-AD subjects that are TRUE positives:  60\n",
      "Number of flagged HPC-AD subjects that are FALSE positives:  8.0\n",
      "Number of true negatives:  180.0\n",
      "#############################\n",
      "Stage 1 stats for TARGET vs NON-TARGET\n",
      "Precision for AD:  0.707865168539\n",
      "Recall (or sensitivity)  for AD:  0.692307692308\n",
      "Specificity:  0.723404255319\n",
      "Adjusted precision for 33.6% baseline rate:  0.558802252068\n",
      "Accuracy:  0.708108108108\n",
      "#############################\n",
      "Stage 2 stats for TARGET vs NON-TARGET\n",
      "Precision for HPC-AD:  0.882352941176\n",
      "Recall (or sensitivity) for HPC-AD:  0.32967032967\n",
      "Specificity:  0.957446808511\n",
      "Adjusted precision for 33.6% baseline rate:  0.796760218497\n",
      "Accuracy:  0.648648648649\n"
     ]
    }
   ],
   "source": [
    "predic_stats(y_, y_pred, lr_decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(370, 96)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Control    188\n",
       "Autism     182\n",
       "Name: DX_GROUP, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['DX_GROUP'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(370, 6)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predic_stats(y_, y_pred, lr_decision):\n",
    "    # number of AD subjects\n",
    "    n_ad = sum(y_)\n",
    "    print('Total number of TARGET subjects: ', n_ad)\n",
    "\n",
    "    # number of CN subjects\n",
    "    n_cn = len(y_) - sum(y_)\n",
    "    print('Total number of NON-TARGET subjects: ', n_cn)\n",
    "    \n",
    "    # number of subjects predicted as AD at stage 1\n",
    "    n_pos = sum(y_pred)\n",
    "    print('Stage 1 number of hits (true and false positives): ', n_pos)\n",
    "    \n",
    "    # true positives at stage 1\n",
    "    n_pos_ad = sum(y_pred[y_.astype(bool)])\n",
    "    print('Stage 1 TRUE positives: ', n_pos_ad)\n",
    "    \n",
    "    # false positives at stage 1\n",
    "    n_pos_cn = n_pos - n_pos_ad\n",
    "    print('Stage 1 FALSE positives: ', n_pos_cn)\n",
    "    \n",
    "    # number of CN subjects not identified as positive (true negatives)\n",
    "    n_neg1_cn = n_cn - n_pos_cn\n",
    "    print('Stage 1 TRUE negatives: ', n_neg1_cn)\n",
    "\n",
    "    # number of all flagged HPC-AD subjects\n",
    "    n_flag = sum(y_pred[lr_decision>0])\n",
    "    print('Total number of flagged HPC-AD subjects: ', n_flag)\n",
    "\n",
    "    # number of flagged HPC-AD subjects who are actually AD (true positives)\n",
    "    n_flag_ad = sum(y_[lr_decision>0])\n",
    "    print('Number of flagged HPC-AD subjects that are TRUE positives: ', n_flag_ad)\n",
    "\n",
    "    # number of flagged HPC-AD subjects that are actually CN (false positives)\n",
    "    n_flag_cn = n_flag - n_flag_ad\n",
    "    print('Number of flagged HPC-AD subjects that are FALSE positives: ', n_flag_cn)\n",
    "\n",
    "    # number of CN subjects that were not flagged (true negatives)\n",
    "    n_neg_cn = n_cn - n_flag_cn\n",
    "    print('Number of true negatives: ', n_neg_cn)\n",
    "    \n",
    "    print('#############################')\n",
    "    print('Stage 1 stats for TARGET vs NON-TARGET')\n",
    "    print('Precision for AD: ', n_pos_ad/(n_pos_ad + n_pos_cn))\n",
    "    print('Recall (or sensitivity)  for AD: ', n_pos_ad/n_ad)\n",
    "    sens = n_pos_ad/n_ad\n",
    "    print('Specificity: ', n_neg1_cn/n_cn)\n",
    "    spec = n_neg1_cn/n_cn\n",
    "    fp = (1-spec)*664\n",
    "    tp = sens*336\n",
    "    adj_prec = tp/(tp+fp)\n",
    "    print('Adjusted precision for 33.6% baseline rate: ', adj_prec)\n",
    "    print('Accuracy: ', (n_pos_ad + n_neg1_cn)/(n_ad + n_cn))\n",
    "\n",
    "    print('#############################')\n",
    "    print('Stage 2 stats for TARGET vs NON-TARGET')\n",
    "    print('Precision for HPC-AD: ', n_flag_ad/n_flag)\n",
    "    print('Recall (or sensitivity) for HPC-AD: ', n_flag_ad/n_ad)\n",
    "    sens_2 = n_flag_ad/n_ad\n",
    "    print('Specificity: ', n_neg_cn/n_cn)\n",
    "    spec_2 = n_neg_cn/n_cn\n",
    "    fp_2 = (1-spec_2)*664\n",
    "    tp_2 = sens_2*336\n",
    "    adj_prec_2 = tp_2/(tp_2 + fp_2)\n",
    "    print('Adjusted precision for 33.6% baseline rate: ', adj_prec_2)\n",
    "    print('Accuracy: ', (n_flag_ad + n_neg_cn)/(n_ad + n_cn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b5e2854a3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(hpc.training_hit_probability,20)\n",
    "plt.ylim(0,300)\n",
    "plt.rcParams.update({'font.size': 18})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some figures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predic_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['hcjoint', 's2df', 'hcdf', 's1df', 'hitproba'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_mask(y_true, y_pred, mask_selected=None):\n",
    "    if mask_selected is None:\n",
    "        mask_selected = np.ones(y_pred.shape).astype(bool)\n",
    "    print('------------------------')\n",
    "    print('Ratio:', y_true[mask_selected].sum()/y_true.sum()) \n",
    "    print('#    : ', y_true[mask_selected].sum()) \n",
    "    print('# true values: ',mask_selected.sum())\n",
    "    print('ACC  : ', np.mean((y_true == y_pred)[mask_selected]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level 1\n",
      "------------------------\n",
      "Ratio: 1.0\n",
      "#    :  182\n",
      "# true values:  370\n",
      "ACC  :  0.708108108108\n"
     ]
    }
   ],
   "source": [
    "print('Level 1')\n",
    "stats_mask(y_, (dic_results['s1df'][:,0]>0).astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-e776d729bb48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpos_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdic_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m's2df'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0macc_s2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtmp_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdic_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m's1df'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": [
    "pos_mask = (dic_results['s2df'][:,1]>0)\n",
    "acc_s2 = metrics.accuracy_score(y_val[tmp_mask], (dic_results['s1df'][:,0]>0).astype(float)[pos_mask])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
